[{"role": "system", "content": ""}, {"role": "user", "content": "```\ndef get_gpt_answer(message, message_sys, temperature, top_p, model):\n    try:\n        full_message = [message_sys] + message\n        response = client.chat.completions.create(\n            model=model,\n            messages=full_message,\n            temperature=temperature,\n            top_p=top_p,\n            frequency_penalty=0,\n            presence_penalty=0,\n            stop=None\n        )\n        answer_str = response.choices[0].message.content\n\n\n    except Exception as e:\n        answer_str = '\u8bf7\u6c42\u56de\u7b54\u65f6\u51fa\u73b0\u9519\u8bef\uff0c\u9519\u8bef\u5185\u5bb9\u4e3a:\\n' + str(e)\n    return answer_str\n```\nget me tokens beside answer"}, {"role": "assistant", "content": "To get the tokens beside the answer in the `get_gpt_answer` function, you can modify the code as follows:\n\n```python\ndef get_gpt_answer(message, message_sys, temperature, top_p, model):\n    try:\n        full_message = [message_sys] + message\n        response = client.chat.completions.create(\n            model=model,\n            messages=full_message,\n            temperature=temperature,\n            top_p=top_p,\n            frequency_penalty=0,\n            presence_penalty=0,\n            stop=None\n        )\n        answer_str = response.choices[0].message.content\n        tokens = response.choices[0].message.tokens\n\n    except Exception as e:\n        answer_str = '\u8bf7\u6c42\u56de\u7b54\u65f6\u51fa\u73b0\u9519\u8bef\uff0c\u9519\u8bef\u5185\u5bb9\u4e3a:\\n' + str(e)\n        tokens = []\n\n    return answer_str, tokens\n```\n\nIn this modified code, the `tokens` variable is assigned the value of `response.choices[0].message.tokens`, which gives you the tokens of the generated answer. The `tokens` list can be returned along with the `answer_str` variable."}]